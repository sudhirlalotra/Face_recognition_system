{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e993226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.22631.3737]\n",
      "(c) Microsoft Corporation. All rights reserved.\n",
      "\n",
      "C:\\Users\\91600\\PycharmProjects\\MINIPROJECT>pip install \"C:\\Users\\91600\\Favorites\\Downloads\\dlib-python whl packages-20240406T131321Z-001\\dlib-python whl packages\\dlib-19.22.99-cp310-cp310-win_amd64.whl\"\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing c:\\users\\91600\\favorites\\downloads\\dlib-python whl packages-20240406t131321z-001\\dlib-python whl packages\\dlib-19.22.99-cp310-cp310-win_amd64.whl\n",
      "dlib is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "\n",
      "C:\\Users\\91600\\PycharmProjects\\MINIPROJECT>"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install \"C:\\Users\\91600\\Favorites\\Downloads\\dlib-python whl packages-20240406T131321Z-001\\dlib-python whl packages\\dlib-19.22.99-cp310-cp310-win_amd64.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df574709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: face-recognition in c:\\users\\91600\\appdata\\roaming\\python\\python310\\site-packages (1.3.0)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from face-recognition) (9.4.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\91600\\appdata\\roaming\\python\\python310\\site-packages (from face-recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from face-recognition) (8.0.4)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\91600\\appdata\\roaming\\python\\python310\\site-packages (from face-recognition) (19.22.99)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from face-recognition) (1.23.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from Click>=6.0->face-recognition) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7480803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634f8971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Encode File ...\n",
      "Encode File Loaded\n",
      "{'last_attendance_time': '2024-06-22 16:46:37', 'major': 'c++', 'name': 'gourav  ', 'standing': 'G', 'starting_year': 2021, 'total_attendance': 4, 'year': 4}\n",
      "1308.965751\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m imgS \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.25\u001b[39m)\n\u001b[0;32m     54\u001b[0m imgS \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(imgS, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 56\u001b[0m faceCurFrame \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m encodeCurFrame \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(imgS, faceCurFrame)\n\u001b[0;32m     59\u001b[0m imgBackground[\u001b[38;5;241m162\u001b[39m:\u001b[38;5;241m162\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m480\u001b[39m, \u001b[38;5;241m55\u001b[39m:\u001b[38;5;241m55\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m640\u001b[39m] \u001b[38;5;241m=\u001b[39m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import cvzone\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import storage\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': \"https://faceattendencerealtime-6a0b8-default-rtdb.firebaseio.com/\",\n",
    "    'storageBucket': \"faceattendencerealtime-6a0b8.appspot.com\"\n",
    "})\n",
    "\n",
    "bucket = storage.bucket()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "# Importing the mode images into a list\n",
    "folderModePath = 'Resources/Modes'\n",
    "modePathList = os.listdir(folderModePath)\n",
    "imgModeList = []\n",
    "for path in modePathList:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "# Load the encoding file\n",
    "print(\"Loading Encode File ...\")\n",
    "file = open('EncodeFile.p', 'rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown, studentIds = encodeListKnownWithIds\n",
    "# print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "imgStudent = []\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "    if faceCurFrame:\n",
    "        for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "            # print(\"matches\", matches)\n",
    "            # print(\"faceDis\", faceDis)\n",
    "\n",
    "            matchIndex = np.argmin(faceDis)\n",
    "            # print(\"Match Index\", matchIndex)\n",
    "\n",
    "            if matches[matchIndex]:\n",
    "                # print(\"Known Face Detected\")\n",
    "                # print(studentIds[matchIndex])\n",
    "                y1, x2, y2, x1 = faceLoc\n",
    "                y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "                bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "                imgBackground = cvzone.cornerRect(imgBackground, bbox, rt=0)\n",
    "                id = studentIds[matchIndex]\n",
    "                if counter == 0:\n",
    "                    cvzone.putTextRect(imgBackground, \"Loading\", (275, 400))\n",
    "                    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "                    cv2.waitKey(1)\n",
    "                    counter = 1\n",
    "                    modeType = 1\n",
    "\n",
    "        if counter != 0:\n",
    "\n",
    "            if counter == 1:\n",
    "                # Get the Data\n",
    "                studentInfo = db.reference(f'Students/{id}').get()\n",
    "                print(studentInfo)\n",
    "                # Get the Image from the storage\n",
    "                blob = bucket.get_blob(f'Images/{id}.png')\n",
    "                array = np.frombuffer(blob.download_as_string(), np.uint8)\n",
    "                imgStudent = cv2.imdecode(array, cv2.COLOR_BGRA2BGR)\n",
    "                # Update data of attendance\n",
    "                datetimeObject = datetime.strptime(studentInfo['last_attendance_time'],\n",
    "                                                   \"%Y-%m-%d %H:%M:%S\")\n",
    "                secondsElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
    "                print(secondsElapsed)\n",
    "                if secondsElapsed > 30:\n",
    "                    ref = db.reference(f'Students/{id}')\n",
    "                    studentInfo['total_attendance'] += 1\n",
    "                    ref.child('total_attendance').set(studentInfo['total_attendance'])\n",
    "                    ref.child('last_attendance_time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                else:\n",
    "                    modeType = 3\n",
    "                    counter = 0\n",
    "                    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "            if modeType != 3:\n",
    "\n",
    "                if 10 < counter < 20:\n",
    "                    modeType = 2\n",
    "\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    \n",
    "                if counter <= 10:\n",
    "                    cv2.putText(imgBackground, str(studentInfo['total_attendance']), (861, 125),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['major']), (1006, 550),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(id), (1006, 493),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['standing']), (910, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['year']), (1025, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['starting_year']), (1125, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "\n",
    "                    (w, h), _ = cv2.getTextSize(studentInfo['name'], cv2.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "                    offset = (414 - w) // 2\n",
    "                    cv2.putText(imgBackground, str(studentInfo['name']), (808 + offset, 445),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 50), 1)\n",
    "\n",
    "                    imgBackground[175:175 + 216, 909:909 + 216] = imgStudent\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                if counter >= 20:\n",
    "                    counter = 0\n",
    "                    modeType = 0\n",
    "                    studentInfo = []\n",
    "                    imgStudent = []\n",
    "                    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    else:\n",
    "        modeType = 0\n",
    "        counter = 0\n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a7471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9871e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e43366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870affd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f555a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
